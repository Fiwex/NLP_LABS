{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# NLP - Lab 04\n",
    "## Adrien Giget, Tanguy Malandain, Denis Stojiljkovic"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Introduction to Natural Language Processing 01\n",
    "\n",
    "Nous allons utiliser FastText pour implémenter classificateur de sentiments."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# FastText (8 points)\n",
    "\n",
    "## Imports"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "start_time": "2023-04-20T16:07:17.955212Z",
     "end_time": "2023-04-20T16:07:19.033133Z"
    }
   },
   "outputs": [],
   "source": [
    "import fasttext\n",
    "from typing import Dict, Any\n",
    "import re\n",
    "\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from datasets import load_dataset\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# instantiate a Pseudo-random number generator (PRNG)\n",
    "rng = np.random.default_rng(420)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-20T16:07:19.035055Z",
     "end_time": "2023-04-20T16:07:19.036319Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Get data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset imdb (/home/adrien/.cache/huggingface/datasets/imdb/plain_text/1.0.0/d613c88cf8fa3bab83b4ded3713f1f74830d1100e171db75bbddb80b3345c9c0)\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/3 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "84914e4ef86b42bcb4ebd2eac3e9ebc6"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = load_dataset(\"imdb\")\n",
    "del dataset[\"unsupervised\"]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-20T16:07:19.040806Z",
     "end_time": "2023-04-20T16:07:20.288827Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### (2 points) Turn the dataset into a dataset compatible with Fastext (see the Tips on using FastText section a bit lower).\n",
    "For pretreatment, only apply lower casing and punctuation removal.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We re-use the code from the previous lab for pretreatment."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def get_lower(comment: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    :param comment: Actual costumer comment as a dict : { str : Any }\n",
    "    :return: a modified dict : { str : Any }\n",
    "    \"\"\"\n",
    "    comment[\"text\"] = comment[\"text\"].lower()\n",
    "    return comment\n",
    "\n",
    "def remove_angle_brackets(comment: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Remove everything inside < > characters (usually <br > from scraping)\n",
    "    :param comment: Actual costumer comment as a dict : { str : Any }\n",
    "    :return: a modified dict : { str : Any }\n",
    "    \"\"\"\n",
    "    comment[\"text\"] = re.sub(f'<.*?>', '', comment[\"text\"])\n",
    "    return comment\n",
    "\n",
    "def remove_unknown_unicode(comment: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Remove all non-usual unicode characters (as —)\n",
    "    :param comment: Actual costumer comment as a dict : { str : Any }\n",
    "    :return: a modified dict : { str : Any }\n",
    "    \"\"\"\n",
    "    comment[\"text\"] = re.sub(r\"(\\\\x\\S+)\", '', repr(comment[\"text\"])[1:-1])\n",
    "    return comment\n",
    "\n",
    "def remove_backslash(comment: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Remove all backslash (usually as \"it\\'s\")\n",
    "    :param comment: Actual costumer comment as a dict : { str : Any }\n",
    "    :return: a modified dict : { str : Any }\n",
    "    \"\"\"\n",
    "    comment[\"text\"] = re.sub(r\"\\\\\", '', comment[\"text\"])\n",
    "    return comment\n",
    "\n",
    "def remove_ponctuation(comment: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Remove non-wanted ponctuations as -_\\(\\)\\\".,`:;* that don't add much syntactical meaning.\n",
    "    :param comment: Actual costumer comment as a dict : { str : Any }\n",
    "    :return: a modified dict : { str : Any }\n",
    "    \"\"\"\n",
    "    comment[\"text\"] = re.sub(r\"[-_\\(\\)\\\".,`:;*]\", ' ', comment[\"text\"])\n",
    "    comment[\"text\"] = re.sub(r\"[(!?)]\", r\" \\g<0> \", comment[\"text\"]) # We want to keep ? and ! in the split\n",
    "    return comment\n",
    "\n",
    "def remove_all(comment: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Apply all above\n",
    "    :param comment: Actual costumer comment as a dict : { str : Any }\n",
    "    :return: a modified dict : { str : Any }\n",
    "    \"\"\"\n",
    "    return remove_ponctuation(remove_backslash(remove_unknown_unicode(remove_angle_brackets(get_lower(comment)))))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-20T16:07:20.288607Z",
     "end_time": "2023-04-20T16:07:20.289114Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/adrien/.cache/huggingface/datasets/imdb/plain_text/1.0.0/d613c88cf8fa3bab83b4ded3713f1f74830d1100e171db75bbddb80b3345c9c0/cache-608093fc9e53df62.arrow\n",
      "Loading cached processed dataset at /home/adrien/.cache/huggingface/datasets/imdb/plain_text/1.0.0/d613c88cf8fa3bab83b4ded3713f1f74830d1100e171db75bbddb80b3345c9c0/cache-76ab34fc70dca627.arrow\n"
     ]
    }
   ],
   "source": [
    "adapted_data = dataset.map(remove_all)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-20T16:07:20.288754Z",
     "end_time": "2023-04-20T16:07:20.376154Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Création des fichiers nécessaires à FastText"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# Charger les données\n",
    "train_data = adapted_data[\"train\"]\n",
    "test_data = adapted_data[\"test\"]\n",
    "\n",
    "# Diviser les données d'entraînement en données d'entraînement et de validation (20% pour la validation)\n",
    "train_data, val_data = train_test_split(train_data, test_size=0.2, random_state=42)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-20T16:07:20.331180Z",
     "end_time": "2023-04-20T16:07:20.488683Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# Créer un dossier 'data' s'il n'existe pas\n",
    "os.makedirs(\"data\", exist_ok=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-20T16:07:20.488990Z",
     "end_time": "2023-04-20T16:07:20.530607Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "# Fonction pour écrire les données dans un fichier FastText\n",
    "def write_fasttext_data(data_text, data_label, filename):\n",
    "    with open(filename, \"w+\", encoding=\"utf-8\") as f:\n",
    "        for index in range(len(data_text)):\n",
    "            label = data_label[index]\n",
    "            text = data_text[index]\n",
    "            f.write(f\"__label__{label} {text}\\n\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-20T16:07:20.530809Z",
     "end_time": "2023-04-20T16:07:20.531120Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "# Écrire les données d'entraînement, de validation et de test dans des fichiers séparés\n",
    "write_fasttext_data(train_data[\"text\"], train_data[\"label\"], \"data/train.txt\")\n",
    "write_fasttext_data(val_data[\"text\"], val_data[\"label\"], \"data/validation.txt\")\n",
    "write_fasttext_data(test_data[\"text\"], test_data[\"label\"], \"data/test.txt\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-20T16:07:20.531022Z",
     "end_time": "2023-04-20T16:07:20.671738Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### (2 points) Train a FastText classifier with default parameters on the training data, and evaluate it on the test data using accuracy."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Read 4M words\n",
      "Number of words:  83253\n",
      "Number of labels: 2\n",
      "Progress: 100.0% words/sec/thread: 3932869 lr: -0.000020 avg.loss:  0.458177 ETA:   0h 0m 0s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.93 s, sys: 122 ms, total: 5.05 s\n",
      "Wall time: 721 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress: 100.0% words/sec/thread: 3930361 lr:  0.000000 avg.loss:  0.458177 ETA:   0h 0m 0s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Entraîner un classificateur FastText avec les paramètres par défaut\n",
    "model = fasttext.train_supervised(\"data/train.txt\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-20T16:07:20.673676Z",
     "end_time": "2023-04-20T16:07:21.398252Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 86.80%\n"
     ]
    }
   ],
   "source": [
    "# Prédire les étiquettes pour les données de test\n",
    "test_predictions = [model.predict(text)[0][0] for text in test_data[\"text\"]]\n",
    "\n",
    "# Calculer l'accuracy\n",
    "correct_predictions = sum(1 for true_label, predicted_label in zip(test_data[\"label\"], test_predictions) if f'__label__{true_label}' == predicted_label)\n",
    "accuracy = correct_predictions / len(test_data[\"label\"])\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.2%}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-20T16:07:21.470537Z",
     "end_time": "2023-04-20T16:07:22.091987Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Malgré que le modèle est appris de façon non supervise, il obtient une très bonne accuracy (bien plus que le modèle du dernier lab).\n",
    "Cela est sans doute dû au fait que FastText capture plus efficace les relations entre les mots que nos modèles probabilistes."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### (2 points) Use the hyperparameters search functionality of FastText and repeat step 2.\n",
    "\n",
    "* To do so, you'll need to split your training set into a training and a validation set.\n",
    "* Let the model search for 5 minutes (it's the default search time).\n",
    "* Don't forget to shuffle (and stratify) your splits. The dataset has its entry ordered by label (0s first, then 1s). Feeding the classifier one class and then the second can mess with its performances.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress: 100.0% Trials:   11 Best score:  0.900800 ETA:   0h 0m 0s\n",
      "Training again with best arguments\n",
      "Read 4M words\n",
      "Number of words:  83253\n",
      "Number of labels: 2\n",
      "Progress:  98.8% words/sec/thread: 1629395 lr:  0.001047 avg.loss:  0.045944 ETA:   0h 0m 0s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1h 16min 17s, sys: 15.4 s, total: 1h 16min 33s\n",
      "Wall time: 5min 20s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress: 100.0% words/sec/thread: 1624233 lr:  0.000000 avg.loss:  0.045442 ETA:   0h 0m 0s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Entraîner un classificateur FastText avec recherche d'hyperparamètres (cela se fait automatiquement quand on utilise train_supervised())\n",
    "model_2 = fasttext.train_supervised(\"data/train.txt\", autotuneValidationFile=\"data/validation.txt\", autotuneDuration=300)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-20T16:07:22.093076Z",
     "end_time": "2023-04-20T16:12:43.007275Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 89.49%\n"
     ]
    }
   ],
   "source": [
    "# Prédire les étiquettes pour les données de test\n",
    "test_predictions_2 = [model_2.predict(text)[0][0] for text in test_data[\"text\"]]\n",
    "\n",
    "# Calculer l'accuracy\n",
    "correct_predictions_2 = sum(1 for true_label, predicted_label in zip(test_data[\"label\"], test_predictions_2) if f'__label__{true_label}' == predicted_label)\n",
    "accuracy_2 = correct_predictions_2 / len(test_data[\"label\"])\n",
    "\n",
    "print(f\"Accuracy: {accuracy_2:.2%}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-20T16:12:43.068002Z",
     "end_time": "2023-04-20T16:12:44.391944Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "On remarque que l'accuracy est légèrement meilleure avec la recherche d'hyperparamètres."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### (1 points) Look at the differences between the default model and the attributes found with hyperparameters search. How do the two models differ?\n",
    "\n",
    "* Only refer to the attributes you think are interesting.\n",
    "* See the Tips on using FastText (just below) for help.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modèle par défaut :\n",
      "  Taux d'apprentissage (lr) : 0.1\n",
      "  Taille du vecteur (dim) : 100\n",
      "  Nombre d'époques (epoch) : 5\n",
      "\n",
      "Modèle avec recherche d'hyperparamètres :\n",
      "  Taux d'apprentissage (lr) : 0.08499425639667486\n",
      "  Taille du vecteur (dim) : 92\n",
      "  Nombre d'époques (epoch) : 100\n"
     ]
    }
   ],
   "source": [
    "# Afficher les attributs intéressants pour les deux modèles\n",
    "print(\"Modèle par défaut :\")\n",
    "print(f\"  Taux d'apprentissage (lr) : {model.lr}\")\n",
    "print(f\"  Taille du vecteur (dim) : {model.dim}\")\n",
    "print(f\"  Nombre d'époques (epoch) : {model.epoch}\")\n",
    "\n",
    "print(\"\\nModèle avec recherche d'hyperparamètres :\")\n",
    "print(f\"  Taux d'apprentissage (lr) : {model_2.lr}\")\n",
    "print(f\"  Taille du vecteur (dim) : {model_2.dim}\")\n",
    "print(f\"  Nombre d'époques (epoch) : {model_2.epoch}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-20T16:12:44.393940Z",
     "end_time": "2023-04-20T16:12:44.395365Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Dans ces deux modèles, la différence d'hyperparamètres vient surtout de la différence du taux d'apprentissage et du nombre d'époques.\n",
    "\n",
    "Mais il est important de rappeler que l'accuracy des deux modèles est très proche. Ainsi, on peut voir la version avancée seulement\n",
    "comme une version ayant apprise plus lentement et plus longtemps que la version par défaut, ce qui permet un fit légèrement plus précis."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### (Bonus point) Why is it likely that the attributes minn and maxn are at 0 after an hyperparameter search on our data?\n",
    "\n",
    "* Hint: on what language are we working?\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Dans le contexte de nos données, il est possible que les valeurs minn et maxn soient fixées à 0 après la recherche d'hyperparamètres, car nous traitons des commentaires rédigés en anglais. Les sous-mots (n-grams) pourraient ne pas être aussi pertinents que pour d'autres langues, telles que les langues agglutinantes. FastText cherche à déterminer les meilleurs hyperparamètres afin de réduire l'erreur de validation. Si les n-grams n'améliorent pas significativement les performances du modèle, la recherche d'hyperparamètres pourrait décider de ne pas les inclure, d'où des valeurs minn et maxn égales à 0."
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
